{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisite: save your Hugging Face token as env var `HF_TOKEN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive for persistent storage\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create a folder for this project's outputs\n",
    "import os\n",
    "DRIVE_OUTPUT_FOLDER = \"/content/drive/MyDrive/gpt-pursuit-results\"\n",
    "os.makedirs(DRIVE_OUTPUT_FOLDER, exist_ok=True)\n",
    "print(f\"‚úÖ Results will be saved to: {DRIVE_OUTPUT_FOLDER}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository (or pull if already exists)\n",
    "REPO_URL = \"https://github.com/ltbrs/gpt-pursuit.git\"  # ‚ö†Ô∏è Update with your repo URL\n",
    "REPO_PATH = \"/content/gpt-pursuit\"\n",
    "\n",
    "if os.path.exists(REPO_PATH):\n",
    "    print(\"üì¶ Repository already cloned, pulling latest changes...\")\n",
    "    !cd {REPO_PATH} && git pull\n",
    "else:\n",
    "    print(\"üì• Cloning repository...\")\n",
    "    !git clone {REPO_URL} {REPO_PATH}\n",
    "    \n",
    "print(f\"‚úÖ Repository ready at: {REPO_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "print(\"üì¶ Installing dependencies...\")\n",
    "%pip install -e .\n",
    "print(\"‚úÖ Dependencies installed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Python path and working directory\n",
    "import sys\n",
    "DATA_ACQ_PATH = os.path.join(REPO_PATH, \"data-acquisition\")\n",
    "sys.path.insert(0, DATA_ACQ_PATH)\n",
    "os.chdir(DATA_ACQ_PATH)\n",
    "print(f\"‚úÖ Working directory: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use relative path (works both locally and on Colab after cd to data-acquisition)\n",
    "question_df = pd.read_csv(\"data/raw/questions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. LLM challenger Answer a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.consts import SELECTED_LLMS\n",
    "from src.answer import answer_questions\n",
    "\n",
    "BATCH_SIZE = 200\n",
    "question_sample = question_df.set_index('id').sample(BATCH_SIZE, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "# Process all LLMs and save results to Google Drive\n",
    "all_results = []\n",
    "\n",
    "for llm_config in SELECTED_LLMS:\n",
    "    model_name = llm_config[\"pipeline_kwargs\"][\"model\"]\n",
    "    print(f\"ü§ñ Processing: {model_name}\")\n",
    "    \n",
    "    question_answers = answer_questions(question_sample[\"Question\"].tolist(), llm_config)\n",
    "    llm_answer_df = pd.DataFrame(question_answers)\n",
    "    llm_answer_df.columns = [cname + \"_\" + model_name for cname in llm_answer_df.columns]\n",
    "    llm_answer_df[\"question_id\"] = question_sample.reset_index()[\"id\"]\n",
    "    \n",
    "    output_path = f\"{DRIVE_OUTPUT_FOLDER}/{uuid.uuid4()}.csv\"\n",
    "    llm_answer_df.to_csv(output_path, index=False)\n",
    "    print(f\"üíæ Saved to: {output_path}\")\n",
    "    \n",
    "    all_results.append(llm_answer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all saved results in Google Drive\n",
    "print(\"üìÇ Files saved to Google Drive:\")\n",
    "for f in sorted(os.listdir(DRIVE_OUTPUT_FOLDER)):\n",
    "    filepath = os.path.join(DRIVE_OUTPUT_FOLDER, f)\n",
    "    size_kb = os.path.getsize(filepath) / 1024\n",
    "    print(f\"  - {f} ({size_kb:.1f} KB)\")\n",
    "    \n",
    "print(f\"\\nüéâ Done! Your results are safely stored in Google Drive at:\")\n",
    "print(f\"   {DRIVE_OUTPUT_FOLDER}\")\n",
    "print(\"\\nYou can close this Colab session - your files will persist in Drive.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
